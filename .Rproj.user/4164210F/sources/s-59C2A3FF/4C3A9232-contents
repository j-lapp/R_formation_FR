
## 6. Analyse
### 6. Analyse avec R

***

#### Liens clés

[Documentation survey](https://www.rdocumentation.org/packages/survey/versions/4.0) <br>
[Documentation srvyr](https://cran.rstudio.com/web/packages/srvyr/srvyr.pdf) <br>
[Introduction à l’analyse d’enquêtes avec R et RStudio](http://larmarange.github.io/analyse-R/) <br>
[Normes minimales et standard de vérifications pour le nettoyage des données](https://www.impact-repository.org/wp-content/uploads/2020/02/IMPACT_Memo_Data-Cleaning-Min-Standards-Checklist_07022020_FR.pdf) <br>
[IMPACT Normes minimales et standards pour la validation d’analyse de données quantitatives](https://www.impact-repository.org/wp-content/uploads/2020/11/IMPACT_Guidance_Prob-Sample-Data-Analysis-Checklist_V2_TO-SHARE_french.pdf) <br>



Modifié de ce [exercise](https://rpubs.com/mabues/R_training_survey_srvyr) <br>


***

Installez et chargez les packages de cette part de l'exercise.
``` {r echo=T, eval=T, warning=FALSE, message=FALSE, error=FALSE}
library(dplyr)
library(srvyr)
library(survey)

```

***

### Introduction
Cette formation se concentre sur la façon d'analyser les données d'enquête dans R. Elle vous apprendra étape par étape comment obtenir les moyennes et les proportions de la population à partir de vos ensembles de données quantitatives, pour les échantillons non pondérés et pondérés (regroupés / stratifiés).

Il ne s’agit pas d’une formation sur le package hypegrammaR de HQ, mais utilise plutôt les célèbres packages R survey et srvyr. srvyr est construit sur l'enquête bien documentée, mais a l'avantage supplémentaire d'utiliser une syntaxe qui peut facilement être combinée avec le paquet de travail dplyr et toutes ses fonctions. De plus, srvyr renvoie les résultats dans un format standardisé, qui peut être plus facile à utiliser qu'une enquête.


Au debut on define deux objets - les donnees comme toujours et cadre d'échantillonnage qui a seulement **2 colonnes**, le nom de strata et le numero de population. Normalment le format de colonne "strata' est comme ca - **unite_de_couverture + groupe_de_population** (ie. est_communaute_hote ou sanmatenga_pdi)

Au debut, on va importer les donnees nettoyees de MSNA et filtrer pour population locale cette fois:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
data <- read.csv("input/donnees/bfa2002_msna_jour35_nettoyage_2020.csv", na.strings = c("NA", "", "N/A"), stringsAsFactors = F) %>% 
  filter(group_pop == "pop_local")
```

Et apres le cadre d'echantillonage (sampling frame). Mais c'est necessaire proceder un peu. On veut faire un analisis au niveau de admin1.
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
sampling_frame <- read.csv("input/echantillon/REACH_BFA_Pop_for_weighting_20201308.csv", na.strings = c("NA", "", "N/A"), fileEncoding="UTF-8-BOM") %>% 
  group_by(admin1) %>% 
  summarize(population = sum(Total.local)) %>% 
  mutate(admin1 = paste0(gsub(" |-", "_", tolower(admin1)), "_pop_local")) %>% 
  rename(strata = admin1)

```

Maintenant on va creer une variable de strata dans les donnees pour faire un join avec le sampling frame.
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
data$strata <- paste0(data$admin1, "_", data$group_pop) 
```

Joigner sampling frame et donnees
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
data <- left_join(data, sampling_frame, by = "strata") 
```

***

### Analyse avec **Survey** 
#### Objet svydesign

Ici on conçoit un objet "design_survey" avec la fonction "svydesign".

L'argument id définit les ID des clusters (du plus grand au plus petit). Dans le cas de l'échantillonnage stratifié uniquement, laissez l'argument vide en spécifiant ~ 1. Définissez l'argument strata comme la colonne que vous avez spécifiée ci-dessus avec les noms de strates (précédés de ~). fpc signifie «population finie correcte» et spécifie la colonne dans laquelle vous avez vos estimations de population. À l'aide de ces estimations, l'enquête calculera des statistiques pondérées.

```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_survey <- svydesign(data = data, id =~1, strata = ~strata, fpc = ~population)
```

***

#### Survey - Analyse sans désagrégation
Avec l'objet design maintenant on peut analyser.

Pour les variables numériques et catégorielles, vous appelez la fonction svymean (). Appelez l'indicateur que vous souhaitez analyser (précédé de ~), ainsi que l'objet de conception de l'enquête. Ajoutez na.rm = TRUE si vous souhaitez exclure toutes les valeurs vides (NA). SE c'est l'erreur standarde.

Un example avec un variable numerique:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
svymean(~ic_age, design_survey, na.rm = TRUE)
```

Et avec une variable catégorique:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
svymean(~situation_matrimoniale, design_survey, na.rm = TRUE)
```
***

#### Survey - Analyse avec désagrégation
Pour analyser avec une désagrégation on appelle la fonction "svyby". C'est comme le suivant ou on define le niveau de désagrégation avec la deuxieme argument:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
svyby(~taille_abri, ~admin1, design_survey, svymean, na.rm=T)
```
***

### Analyse avec **srvyr** 
Le package 'srvyr' s'appuie sur survey, ajoutant la capacité d'utiliser les fonctions dyplyr. 
#### Objet svydesign

Avec le package srvyr on define l'objet de survey design comme ca:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr <- data %>% 
  as_survey_design(ids = 1, strata = strata, fpc = population)
```
***

#### Valeurs numeriques - sans désagrégation
Ici on va utiliser les fonctions de dplyr ensemble avec survey_mean:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  summarise(mean = survey_mean(ic_age, na.rm = TRUE))
```

***

#### Valeurs numeriques - avec désagrégation
Ici on va utiliser le group_by de dplyr ensemble avec survey_mean:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  group_by(admin1) %>%
  summarise(mean = survey_mean(taille_abri, na.rm = TRUE, vartype = "ci"))
```

Notez que dans la sortie des résultats, il y a maintenant 4 colonnes: 1) désagrégations, 2) moyenne, 3) borne inférieure de l'intervalle de confiance et 4) borne supérieure de l'intervalle de confiance (niveau de confiance de 0,95 par défaut).

Les intervalles de confiance (IC) peuvent être utiles pour déterminer rapidement si les différences entre les groupes sont statistiquement significatives. Si les IC ne se chevauchent pas, la différence est statistiquement significative. Si les CI se chevauchent, vous devrez peut-être exécuter un test de signification pour le savoir.

***

#### Valeurs catégorielles - sans désagrégation
Ici encore on utilise le group by:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  group_by(genre_chef_menage) %>%
  summarise(mean = survey_mean(vartype = "ci"))
```

***

#### Valeurs catégorielles - avec désagrégation
Ici encore on utilise le group by mais avec tous les variables (la variable de désagrégation primiere). On utilise filtrer
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  group_by(admin1, ic_genre) %>%
  summarise(mean  = survey_mean(vartype = "ci"))
```


#### Adjouter un nombre
Valeurs numeriques. Adjouter un mutate avec le nom "count":
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  group_by(admin1) %>% 
  summarise(mean  = survey_mean(ic_age, na.rm = TRUE, vartype = "ci"),
            count = unweighted(sum(!is.na(ic_age))))
```


Et valeurs catégorielles
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
design_srvyr %>%
  group_by(admin1, ic_genre) %>%
  summarise(mean  = survey_mean(vartype = "ci"),
            count = unweighted(n()))
```


### Analyse avec HypegrammaR
Le package hypegrammaR a été créé par IMPACT HQ pour soutenir l'analyse quantitative en R. Il met en œuvre les [directives d'analyse quantitative des données IMPACT](https://www.impact-repository.org/wp-content/uploads/2020/11/IMPACT_Guidance_Prob-Sample-Data-Analysis-Checklist_V2_TO-SHARE_french.pdf)
<br>
Il est fortement recommandé d'inclure des dossiers séparés «input» et «output» dans votre projet de HypegrammaR. Le dossier «input» contient le questionnaire, la base de sondage, les données nettoyées, le plan d'analyse. Le dossier «output» contient les résultats de l'analyse.

#### Installez et chargez Hypegrammar
``` {r echo=T, eval=F, warning=FALSE, message=FALSE, error=FALSE}
library(devtools)
devtools::install_github("https://github.com/impact-initiatives/hypegrammaR")
```

``` {r echo=T, eval=T, warning=FALSE, message=FALSE, error=FALSE}
library(hypegrammaR)
```

***

#### Le dossier «input»

**Données d'évaluation nettoyées**
* Il est essentiel que les noms de colonne de l'ensemble de données utilisent les noms kobo **(XML values as headers)**.
* Si vous avez ajouté de nouvelles variables recodées dans votre ensemble de données, il est recommandé de les ajouter en tant que lignes supplémentaires au questionnaire, en spécifiant le type de variable, les choix, etc.
* Assurez-vous que les informations personnellement identifiées et les données sensibles sont supprimées de l'ensemble de données nettoyé.

Pour cet exercise on va utiliser les donnees de MSNA comme ci-dessus, et faire cette analyse avec **seulement le groupe de populaion locale.


**Cadre d'échantillonnage** -- qui a seulement **2 colonnes**, le nom de strata et le numero de population. 

* Normalment le format de colonne "strata' est comme ca - **unite_de_couverture + groupe_de_population** (ie. est_communaute_hote ou sanmatenga_pdi). Ici on n'a pas des statistiques pour les autres population donc on va incluye seulement le population local aussi.

**Outil**
Maintenant on importe les questions et les choix de l'outil:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
questions       <- readxl::read_excel("input/outil/bfa_msna_outil_V2.xlsx", sheet="survey")
choices      <- readxl::read_excel("input/outil/bfa_msna_outil_V2.xlsx", sheet="choices")
```

**plan d'analyse des données (DAP)**
The data analysis plan should have nine columns, as outlined in the file below:
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
dap    <- read.csv("input/dap/dap_msna2020.csv")
head(dap)
```

***


#### Chargez les fichiers

``` {r echo=T, eval=T, warning=FALSE, message=FALSE, error=FALSE}

assessment_data <- load_data(file = "input/donnees/bfa2002_msna_jour35_nettoyage_2020.csv") %>% 
    filter(group_pop == "pop_local" | group_pop == "pdi")
sampling_frame_final  <- load_samplingframe(file ="input/echantillon/sampling_frame_clean.csv")
questionnaire   <- load_questionnaire(data = assessment_data,
                                      questions = questions,
                                      choices = choices,
                                      choices.label.column.to.use = "label"
                                      )
analysisplan    <- load_analysisplan("input/dap/dap_msna2020.csv")
``` 

Ensuite, definez la variable de stratification entre les donnees et le cadre d'echantillonage. Parallèle q'on a fait avec le preparation en utilisant le package survey.

Apres creez la variable de strata dans les donnees.
```{r echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}
assessment_data$strata <- paste0(assessment_data$admin1, "_", assessment_data$group_pop) 
```

#### Maintenant on peut appeler le poids avec la fonction **"map_to_weighting"**
Ici c'est important specifier le colonne specifique pour joigner les donnes avec l'echantillon.
``` {r echo=T, eval=T, warning=FALSE, message=FALSE, error=FALSE}
weights <- map_to_weighting(sampling.frame = sampling_frame_final,
                            data.stratum.column = "strata", # la colonne strata pour joigner cote des donnees
                            sampling.frame.population.column = "population", # colonne avec population dans l'echantillon
                            sampling.frame.stratum.column = "strata"  # la colonne strata pour joigner cote d'echantillon
                            )
```

**Calculs non pondérés**: si votre évaluation n’est pas stratifiée / pondérée, il n’est pas nécessaire de charger une base de sondage à l’étape 2. Vous devrez également supprimer les étapes 3 et 4, et supprimer la ligne «pondération» à l’étape 5.

#### Lancer l'analyse
``` {r eval=TRUE, include=FALSE}
results <- from_analysisplan_map_to_output(assessment_data, 
                                          analysisplan = analysisplan,
                                          weighting = weights,
                                          questionnaire = questionnaire, 
                                          confidence_level = 0.9)
```

``` {r eval=FALSE, include=TRUE}
results <- from_analysisplan_map_to_output(assessment_data, 
                                          analysisplan = analysisplan,
                                          weighting = weights,
                                          questionnaire = questionnaire, 
                                          confidence_level = 0.9)
```
#### Exportez les résultats
map_to_master_table()
``` {r eval=TRUE, include=FALSE}
results_output <- map_to_master_table(results$results, "output/analysis_results.csv")

```

``` {r eval=FALSE, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}

results_output <- map_to_master_table(results$results, "output/analysis_results.csv")
```

``` {r eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE}

head(results_output)
```